âœ… Data Cleaning: The Full Process

Data cleaning (or data cleansing) is a crucial step in the data science pipeline. It ensures that the raw data becomes accurate, consistent, and usable for analysis and modeling.

1ï¸âƒ£ Data Collection & Initial Loading

Data is collected from various sources: CSV files, databases, APIs, logs, sensors, etc.

Loaded into tools like Pandas (Python), R, Excel, or a database.

2ï¸âƒ£ Data Inspection & Profiling

Explore the dataset to understand its structure:

Number of rows and columns

Data types of each column

Basic descriptive statistics (mean, median, min, max, std deviation)

Check for missing values, duplicate rows, outliers

Tools Used:

df.head(), df.info(), df.describe() in Pandas

Pandas Profiling / Sweetviz â†’ Automated report generation

3ï¸âƒ£ Handling Missing Values

âš¡ Common Issues:

Missing entries (empty cells, NaN, NULL)

Approaches:

âŒ Remove rows with missing values (df.dropna()).

âœ… Fill missing values with:

Mean or median (for numerical columns).

Mode or constant (for categorical columns).

Advanced: Predict missing values using models (KNN Imputer).

Example:

df['Age'].fillna(df['Age'].mean(), inplace=True)

4ï¸âƒ£ Handling Duplicates

â— Duplicated rows may occur due to data collection errors.

Remove duplicates:

df.drop_duplicates(inplace=True)

5ï¸âƒ£ Standardizing Data Formats

Normalize text case â†’ lowercase all strings.

Standardize date formats â†’ Convert to datetime type:

df['Date'] = pd.to_datetime(df['Date'], format='%Y-%m-%d')

6ï¸âƒ£ Handling Outliers

Detect outliers using statistical methods:

Z-score method â†’ Flag values beyond Â±3 standard deviations.

IQR method â†’ Data outside [Q1 - 1.5Ã—IQR, Q3 + 1.5Ã—IQR].

Decide:

âŒ Remove outliers.

âœ… Cap extreme values (Winsorization).

Example (IQR method):

Q1 = df['Sales'].quantile(0.25)
Q3 = df['Sales'].quantile(0.75)
IQR = Q3 - Q1
df = df[(df['Sales'] >= Q1 - 1.5 * IQR) & (df['Sales'] <= Q3 + 1.5 * IQR)]

7ï¸âƒ£ Encoding Categorical Variables

Convert categories into numerical form:

Label Encoding (e.g., 'Male' â†’ 0, 'Female' â†’ 1).

One-Hot Encoding (create binary columns).

Example (One-Hot Encoding):

df = pd.get_dummies(df, columns=['Gender'])

8ï¸âƒ£ Feature Scaling

Normalize numerical features to the same scale:

StandardScaler (mean=0, std=1).

MinMaxScaler (scale between 0 and 1).

Example:

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
df[['Sales', 'Marketing_Spend']] = scaler.fit_transform(df[['Sales', 'Marketing_Spend']])

9ï¸âƒ£ Handling Inconsistent Data

Correct typos in categorical data (e.g., 'New York', 'new york', 'NY' â†’ 'New York').

Validate data types: Ensure columns contain only expected types.

ðŸ”Ÿ Final Verification

Validate the cleaned dataset:

No missing values: df.isnull().sum()

No duplicate rows: df.duplicated().sum()

Data types are correct

All necessary transformations are applied

âœ… Why Data Cleaning Is Important

Prevents garbage-in, garbage-out (GIGO) problem.

Improves model accuracy and performance.

Helps uncover true patterns and relationships.

Makes data easier to analyze and visualize.